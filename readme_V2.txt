Readme file for ECOF V1.0


The ECOF (Environment Canada's Optimal Fingerprint) package is coded by Feng, Yang (yang.feng@ec.gc.ca) with technical support and scientific review by Qiuzi Han Wen (HanQiuzi.Wen@ec.gc.ca).


Main functions

This package contains R functions to conduct detection and attribution analysis using three different algorithms under the optimal fingerprint framework. These include:

1.ols(Y,X,noise1,noise2,nsig,df2=NULL,plev), the Ordinary Least Squares method (Allen and Tett, 1999). 

2.tls.A03 (Y, X, noise1, noise2, nsig, nsim.CI, df2, REG=FALSE, plev), the Total Least Squares method (Allen and Scott, 2003). Note that the confidence intervals for the scaling factors are obtained using the method provided in the ROF package by Dr. A. Ribes (Ribes, A., 2012)  

3.tls.ROF (Y, X, noise1, noise2, nsig, nsim.CI, nsim.rcc, REG=TRUE, df2, plev, rcc.flg), the Regularized Optimal Fingerprint method (Ribes et al, 2013a). This function is translated from routines in the ROF package V0.8 coded by Dr. A. Ribes, using SCILAB. (Ribes, A., 2012)


Data input

All three functions take input from an R S4 object generated by function readin(file01, file02, file03). This function reads three data files, i.e., observations and model simulated signal/s (file01), the first set of samples for estimating internal variability (file02), and a second set of such samples (file03). The first line in file01 contains observations (separated by spaces), and the remaining lines represent signal/s (one line per signal).  Similarly, each line in file02 and file03 represents one realization of internal variability, i.e., one noise piece.  


Parameters

A user needs to provide several parameters as input, and these parameters can be shared by all three functions (when applicable).

REG -- a logical value, default is TRUE, if regularization should be performed to estimate the internal variability for optimization

df2 -- number of degrees of freedom for the second estimate of internal variability. The default value is the number of lines in file03. If lines in file03 are not independent, df2 need to be calculated accordingy.  

nsim.CI -- number of Monte Carlo simulations performed  to estimate confidence interval of scaling factor/s

nsim.rcc -- number of simulations required to generate the empirical null distribution of residual consistency check statistics 

plev  -- the confidence level of the confidence interval or the confidence region. In ols(), plev refer to the confidence level for the upper confidence limit of confidence intervals, and the lower confidence level is then set to be 1-plev. The default in ols() is 0.95, producing 5-95% confidence interval (region). In tls.A03() and tls.ROF(), plev sets the confidence level for confidence regions. In this case, the default value is 0.9, which again produces 5-95% confidence intervals (regions).  

nsig -- ensemble number(s) for calculating the signal(s), with NO DEFAULT. It's a vector whose length equals to the number of signals in file01. 


Result visualization

1.plotbetas(fit), display the scaling factor(s) and its (their mariginal) confidence interval(s).

2.plotrstat(fit), display the results of residual consistency check.


Reduce dimension operation

When data are centered (either relative to the full period of record or a fixed base period), the effective dimension of the data vector is reduced by 1.  That is, a de-meaned nt-dimensional data vector x resides in an nt-1 dimensional vector space via the constraint that x'j = 0, where j is the nt-dimensional vector that describes the de-meaning (centering) operation.  The purpose of the reduce-dimension operation is to transform nt-dimensional data vectors that have been de-meaned into nt-1 dimensional vectors that contain the equivalent information. It assumes that ns demeaned nt-dimensional vectors are organized into a matrix with nt*ns entries, with the organization of the matrix (time in rows vs time in columns) indicated by the logical variable timefirst, and with the based period that was used to de-mean the data specified by starting and ending indices p1 and p2.

Note: the code to perform this operation is translated from routine proj_FullRank(T,S) in the ROF package (Ribes, A., 2012) with some modification. Our modification allows the user to define the base period, while the original proj_FullRank() in ROF treats the full time frame as the base period. However, the base period specified by the user must be consistent with the base period of the input data. 

This operation can be realized by two functions:

1) redop(nt, p1, p2), generate a reduce-dimension-operator u in the time domain based on user supplied information of temporal structure of data, i.e., with the based period that was used to demean the data specified by starting and ending indices p1 and p2.

2a) redvec(u, x, nt, ns, timefirst=T), apply the temporal operator u to the spatiotemporal data vector (matrix). It assumes that ns demeaned nt-dimensional vectors are organized into a matrix with nt*ns entries, with the organization of the matrix (time in rows vs time in columns) indicated by the logical variable timefirst. All input data can be processed together by calling: readECOF(idata, u, nt, ns, timefirst=T), where idata is the R S4 object generated by readin(). 

2b) redECOF<-function(x,u,nt,ns,timefirst=T), a function to reduce the dimension of all data vectors {Y,X,noise1,noise2} in a ECOF object x and return a new ECOF object x_red which contains dimension-reduced elements {Y_red,X_red,noise1_red,noise2_red}.

Examples

# # read-in data files generate R S4 object for analysis. ‘obs_sig.dat’ contains observed (the first row) and CMIP5 simulated historical (the second row) 5yr mean precipitation anomaly averaged over the northern high latitude region (50N-90N) during 1966-2005. The anomaly is calculated relative to climatology of 1966-1995. The CMIP5 historical (ALL) signal is calculated from a 32-model ensemble which contains 158 runs all together. ‘noise1.dat’ and ‘noise2.dat’ each contain 302 samples for estimating internal variability obtained primarily from CMIP5 unforced control runs (see Zhang et al 2014 for details). Each line in the three data files is a data vector of length 8. Please refer to the following reference for more details in data processing: Zhang,X., H. Wan, F.W. Zwiers, S.-K. Min, 2014: Attributing Northern high-latitude precipitation change over the period 1966-2005 to human influence. Submitted.

Z0<-readin('obs_sig.dat','noise1.dat','noise2.dat')

# # reduce dimension if data vector is centered, i.e., anomaly calculated w.r.t a base period that is contained in the study period.

# # generate reduce dimension operator

u=redop(nt, p1, p2)

# # apply the operator to obtain the dimension reduced data object

Z=redECOF(Z0, u, nt, ns, timefirst=T) 

# Apply ols analysis using default parameters of df2=nrow(noise2) and plev=0.95; results stored in o.ols.

o1.ols<-ols(Z@Y,Z@X,Z@noise1,Z@noise2,nsig=158)

plotbetas(o1.ols)

plot_RCC(o1.ols)

# Apply tls.A03 using default degree of freedom for noise2 and plev (0.9) 

o1.tls<-tls.A03(Z@Y,Z@X,Z@noise1,Z@noise2,nsig=158, nsim.ci=1000, REG=F)

plotbetas(o1.tls)

plot_RCC(o1.tls)

# Apply tls.ROF using default degree of freedom for noise2 and plev (0.9)

o1.rof<-tls.ROF(Z@Y,Z@X,Z@noise1,Z@noise2,nsig=158, nsim.CI=1000,REG=T, rcc.flg=T, nsim.rcc=1000)

plotbetas(o1.rof)


Reference

1.Allen, M.R., and S.F.B. Tett, 1999: Checking for model consistency in optimal fingerprinting. Clim. Dyn., 15, 419-434.

2.Allen, M.R., and P.A. Stott, 2003: Estimating signal amplitudes in optimal fingerprinting, Part I: Theory. Clim. Dyn., 21, 477-491

3.Ribes A, Planton S, Terray L, 2013a: Application of regularized optimal fingerprinting to attribution. Part I: method, properties and idealized analysis. Clim Dyn, doi:10.1007/s00382-013-1735-7

4.Ribes A, 2012: ROF routines: Scientific document  V0.8.
